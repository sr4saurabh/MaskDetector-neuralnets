{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in d:\\anaconda\\lib\\site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'D:\\ANACONDA\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\PIL\\Image.py:989: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images loaded: 3833\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "imagePaths = list(paths.list_images('./input/face-mask-detection-data'))\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    image = load_img(imagePath, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "print(\"No. of images loaded: {}\".format(len(data)))\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 108s 1s/step - loss: 0.3855 - accuracy: 0.8724 - val_loss: 0.1720 - val_accuracy: 0.9752\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 101s 1s/step - loss: 0.1487 - accuracy: 0.9661 - val_loss: 0.0930 - val_accuracy: 0.9804\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 101s 1s/step - loss: 0.1008 - accuracy: 0.9763 - val_loss: 0.0667 - val_accuracy: 0.9817\n",
      "Epoch 4/20\n",
      "29/95 [========>.....................] - ETA: 59s - loss: 0.0837 - accuracy: 0.9741 "
     ]
    }
   ],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "    test_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "    target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = list(paths.list_images('./my_input/withmask'))\n",
    "\n",
    "newpath = newpath[0]\n",
    "img = load_img(newpath)\n",
    "img = img_to_array(img)\n",
    "img = cv2.resize(img,(224,224))\n",
    "img = img.reshape(1,224,224,3)\n",
    "\n",
    "img = preprocess_input(img)\n",
    "#print(img.shape)\n",
    "img = np.array(img, dtype=\"float32\")\n",
    "pred = model.predict(img)\n",
    "#print(pred)\n",
    "if(pred[0][0] > pred[0][1]):\n",
    "    print(\"mask detected\")\n",
    "else:\n",
    "    print(\"mask not detected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
